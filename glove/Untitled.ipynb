{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41d3173-5503-4f1d-aac7-824fa7c4efe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter path to image folder (e.g., ./sample_images):  ./sample_images\n",
      "Enter YOLO model path (.pt, e.g., yolov8n.pt):  yolov8n.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\images.jpg: 352x640 (no detections), 213.9ms\n",
      "Speed: 6.5ms preprocess, 213.9ms inference, 1.4ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\img1.jpg: 448x640 1 person, 204.3ms\n",
      "Speed: 5.0ms preprocess, 204.3ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\img2.jpg: 512x640 1 person, 221.5ms\n",
      "Speed: 4.4ms preprocess, 221.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\img3.jpg: 480x640 1 person, 235.6ms\n",
      "Speed: 3.5ms preprocess, 235.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\img4.jpg: 640x544 1 person, 183.2ms\n",
      "Speed: 5.4ms preprocess, 183.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\img5.jpg: 576x640 1 person, 203.4ms\n",
      "Speed: 7.2ms preprocess, 203.4ms inference, 2.3ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\img6.jpg: 640x640 1 toothbrush, 221.4ms\n",
      "Speed: 7.2ms preprocess, 221.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\img7.jpg: 640x640 1 person, 1 bed, 242.3ms\n",
      "Speed: 8.0ms preprocess, 242.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\img8.jpg: 448x640 1 person, 217.3ms\n",
      "Speed: 3.6ms preprocess, 217.3ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 E:\\coding\\Data Science\\opencv\\glove\\sample_images\\img9.jpg: 448x640 2 persons, 175.9ms\n",
      "Speed: 5.2ms preprocess, 175.9ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Done! Check ./output and ./logs\n"
     ]
    }
   ],
   "source": [
    "import os, json, cv2\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def run_detection(input_folder, model_path, output_folder, logs_folder):\n",
    "    Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    Path(logs_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model = YOLO(model_path)\n",
    "    all_results = []\n",
    "\n",
    "    for img_file in Path(input_folder).glob(\"*\"):\n",
    "        if img_file.suffix.lower() not in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(str(img_file))\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read {img_file}\")\n",
    "            continue\n",
    "\n",
    "        results = model(str(img_file))\n",
    "        dets = []\n",
    "\n",
    "        for box in results[0].boxes:\n",
    "            cls_index = int(box.cls[0])\n",
    "            label = model.names[cls_index]\n",
    "\n",
    "            # Simulate gloved/bare detection: only use \"person\" class for demo\n",
    "            if label != \"person\":\n",
    "                continue\n",
    "\n",
    "            conf = float(box.conf[0])\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "            # Fake logic for demo: even x1 -> gloved, odd x1 -> bare\n",
    "            hand_label = \"gloved_hand\" if x1 % 2 == 0 else \"bare_hand\"\n",
    "\n",
    "            dets.append({\"label\": hand_label, \"confidence\": conf, \"bbox\": [x1, y1, x2, y2]})\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "            cv2.putText(img, f\"{hand_label} {conf:.2f}\", (x1, y1-5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "\n",
    "        cv2.imwrite(str(Path(output_folder)/img_file.name), img)\n",
    "\n",
    "        log = {\"filename\": img_file.name, \"detections\": dets}\n",
    "        with open(Path(logs_folder)/(img_file.stem+\".json\"), \"w\") as f:\n",
    "            json.dump(log, f, indent=2)\n",
    "        all_results.append(log)\n",
    "\n",
    "    with open(Path(logs_folder)/\"all_detections.json\", \"w\") as f:\n",
    "        json.dump({\"images\": all_results}, f, indent=2)\n",
    "\n",
    "    print(\"Done! Check\", output_folder, \"and\", logs_folder)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = input(\"Enter path to image folder (e.g., ./sample_images): \")\n",
    "    model_path = input(\"Enter YOLO model path (.pt, e.g., yolov8n.pt): \")\n",
    "\n",
    "    run_detection(\n",
    "        input_folder=input_folder,\n",
    "        model_path=model_path,\n",
    "        output_folder=\"./output\",\n",
    "        logs_folder=\"./logs\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a9dfe-ffd8-4f24-becd-22261c8b39a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
